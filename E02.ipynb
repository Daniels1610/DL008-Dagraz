{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E02 Notebook - Daniel Agraz Vallejo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **E2.1:** Employing Tensorflow conduct the logic operation on each of the displayed examples.\n",
    "\n",
    "<img src='imgs/E2.1Examples.png' alt='E2.1 Ejemplos'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buffer(A:tf.Tensor) -> tf.Tensor:\n",
    "    io_description(A, B=None)\n",
    "    return A\n",
    "\n",
    "# Logical AND\n",
    "def land(A:tf.Tensor, B:tf.Tensor) -> tf.Tensor: \n",
    "    io_description(A,B)\n",
    "    return tf.logical_and(A, B)\n",
    "\n",
    "# Logical OR\n",
    "def lor(A:tf.Tensor, B:tf.Tensor) -> tf.Tensor:\n",
    "    io_description(A,B)\n",
    "    return tf.logical_or(A, B)\n",
    "\n",
    "# Logical NOT | tf.logical.not()\n",
    "\n",
    "# Logical Function \n",
    "def logic_func(A:tf.Tensor, B:tf.Tensor) -> tf.Tensor:\n",
    "    io_description(A,B)\n",
    "    return tf.logical_and(A, tf.logical_not(B))\n",
    "\n",
    "def io_description(A:tf.Tensor, B:tf.Tensor):\n",
    "    if B is None: print(f'IN: A-{A}')\n",
    "    else: print(f'IN: A-{A} | B-{B}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 18:49:19.281365: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-02-12 18:49:19.281403: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-02-12 18:49:19.281417: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-02-12 18:49:19.281810: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-02-12 18:49:19.282258: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "A0 = B0 = tf.constant(False, dtype=tf.bool)\n",
    "A1 = B1 = tf.constant(True, dtype=tf.bool)\n",
    "tv0 = tf.Variable([(A0,B0),(A0,B1),(A1,B0),(A1,B1)])\n",
    "\n",
    "\n",
    "A20 = B20 = tf.constant([False,False], dtype=tf.bool)\n",
    "A21 = B21 = tf.constant([False,True], dtype=tf.bool)\n",
    "A22 = B22 = tf.constant([True,False], dtype=tf.bool)\n",
    "A23 = B23 = tf.constant([True,True], dtype=tf.bool)\n",
    "tvA = tf.Variable([A20,A21,A22,A23])\n",
    "tvB = tf.Variable([B20,B21,B22,B23])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Buffer | C = A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBuffer:\u001b[0m\n",
      "IN: A-False\n",
      "OUT: False\n",
      "\n",
      "IN: A-True\n",
      "OUT: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'\\033[1mBuffer:\\033[0m')\n",
    "print(f'OUT: {buffer(A0)}\\n')\n",
    "print(f'OUT: {buffer(A1)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logical AND | C = A $\\land$ B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mLogical AND:\u001b[0m\n",
      "IN: A-False | B-False\n",
      "OUT: False\n",
      "\n",
      "IN: A-False | B-True\n",
      "OUT: False\n",
      "\n",
      "IN: A-True | B-False\n",
      "OUT: False\n",
      "\n",
      "IN: A-True | B-True\n",
      "OUT: True\n",
      "\n",
      "IN: A-[False False] | B-[False False]\n",
      "OUT: [False False]\n",
      "\n",
      "IN: A-[False False] | B-[False  True]\n",
      "OUT: [False  True]\n",
      "\n",
      "IN: A-[False False] | B-[ True False]\n",
      "OUT: [ True False]\n",
      "\n",
      "IN: A-[False False] | B-[ True  True]\n",
      "OUT: [ True  True]\n",
      "\n",
      "IN: A-[False  True] | B-[False False]\n",
      "OUT: [False  True]\n",
      "\n",
      "IN: A-[False  True] | B-[False  True]\n",
      "OUT: [False  True]\n",
      "\n",
      "IN: A-[False  True] | B-[ True False]\n",
      "OUT: [ True  True]\n",
      "\n",
      "IN: A-[False  True] | B-[ True  True]\n",
      "OUT: [ True  True]\n",
      "\n",
      "IN: A-[ True False] | B-[False False]\n",
      "OUT: [ True False]\n",
      "\n",
      "IN: A-[ True False] | B-[False  True]\n",
      "OUT: [ True  True]\n",
      "\n",
      "IN: A-[ True False] | B-[ True False]\n",
      "OUT: [ True False]\n",
      "\n",
      "IN: A-[ True False] | B-[ True  True]\n",
      "OUT: [ True  True]\n",
      "\n",
      "IN: A-[ True  True] | B-[False False]\n",
      "OUT: [ True  True]\n",
      "\n",
      "IN: A-[ True  True] | B-[False  True]\n",
      "OUT: [ True  True]\n",
      "\n",
      "IN: A-[ True  True] | B-[ True False]\n",
      "OUT: [ True  True]\n",
      "\n",
      "IN: A-[ True  True] | B-[ True  True]\n",
      "OUT: [ True  True]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'\\033[1mLogical AND:\\033[0m')\n",
    "for bools in tv0:\n",
    "    print(f'OUT: {land(bools[0],bools[1])}\\n')\n",
    "\n",
    "for boolA in tvA:\n",
    "    for boolB in tvB:\n",
    "        print(f'OUT: {lor(boolA, boolB)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logical OR C = A $\\lor$ B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mLogical OR:\u001b[0m\n",
      "IN: A-False | B-False\n",
      "OUT: False\n",
      "\n",
      "IN: A-False | B-True\n",
      "OUT: True\n",
      "\n",
      "IN: A-True | B-False\n",
      "OUT: True\n",
      "\n",
      "IN: A-True | B-True\n",
      "OUT: True\n",
      "\n",
      "IN: A-[False False] | B-[False False]\n",
      "OUT: [False False]\n",
      "\n",
      "IN: A-[False False] | B-[False  True]\n",
      "OUT: [False  True]\n",
      "\n",
      "IN: A-[False False] | B-[ True False]\n",
      "OUT: [ True False]\n",
      "\n",
      "IN: A-[False False] | B-[ True  True]\n",
      "OUT: [ True  True]\n",
      "\n",
      "IN: A-[False  True] | B-[False False]\n",
      "OUT: [False  True]\n",
      "\n",
      "IN: A-[False  True] | B-[False  True]\n",
      "OUT: [False  True]\n",
      "\n",
      "IN: A-[False  True] | B-[ True False]\n",
      "OUT: [ True  True]\n",
      "\n",
      "IN: A-[False  True] | B-[ True  True]\n",
      "OUT: [ True  True]\n",
      "\n",
      "IN: A-[ True False] | B-[False False]\n",
      "OUT: [ True False]\n",
      "\n",
      "IN: A-[ True False] | B-[False  True]\n",
      "OUT: [ True  True]\n",
      "\n",
      "IN: A-[ True False] | B-[ True False]\n",
      "OUT: [ True False]\n",
      "\n",
      "IN: A-[ True False] | B-[ True  True]\n",
      "OUT: [ True  True]\n",
      "\n",
      "IN: A-[ True  True] | B-[False False]\n",
      "OUT: [ True  True]\n",
      "\n",
      "IN: A-[ True  True] | B-[False  True]\n",
      "OUT: [ True  True]\n",
      "\n",
      "IN: A-[ True  True] | B-[ True False]\n",
      "OUT: [ True  True]\n",
      "\n",
      "IN: A-[ True  True] | B-[ True  True]\n",
      "OUT: [ True  True]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'\\033[1mLogical OR:\\033[0m')\n",
    "for bools in tv0:\n",
    "    print(f'OUT: {lor(bools[0],bools[1])}\\n')\n",
    "\n",
    "for boolA in tvA:\n",
    "    for boolB in tvB:\n",
    "        print(f'OUT: {lor(boolA, boolB)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logical Function #1 | C = A $\\lor\\;\\neg$ B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'\\033[1mLogical Function:\\033[0m')\n",
    "for bools in tv0:\n",
    "    print(f'OUT: {logic_func(bools[0],bools[1])}\\n')\n",
    "\n",
    "for boolA in tvA:\n",
    "    for boolB in tvB:\n",
    "        print(f'OUT: {logic_func(boolA, boolB)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **E2.2:** Implement scikit-learn's perceptron to classify flowers from the Iris Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>class label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     petal length (cm)  petal width (cm)  class label\n",
       "0                  1.4               0.2            0\n",
       "1                  1.4               0.2            0\n",
       "2                  1.3               0.2            0\n",
       "3                  1.5               0.2            0\n",
       "4                  1.4               0.2            0\n",
       "..                 ...               ...          ...\n",
       "145                5.2               2.3            2\n",
       "146                5.0               1.9            2\n",
       "147                5.2               2.0            2\n",
       "148                5.4               2.3            2\n",
       "149                5.1               1.8            2\n",
       "\n",
       "[150 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "df_iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df_iris.insert(4, 'class label', iris.target.reshape(-1,1))\n",
    "df_iris = df_iris[['petal length (cm)', 'petal width (cm)', 'class label']]\n",
    "df_iris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000\n"
     ]
    }
   ],
   "source": [
    "X = iris.data[:, (2,3)]\n",
    "y = (iris.target == 0).astype(int)\n",
    "model = Perceptron(tol=1e-3, random_state=1)\n",
    "model.fit(X, y)\n",
    "print(\"%0.3f\" % model.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 | Iris-Setosa\n",
    "# 0 | Not Iris-Setosa\n",
    "X_test = np.array([[2.0, 0.5],\n",
    "                   [3.6, 1.1],\n",
    "                   [4.9, 1.9]])\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 150)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scratch Implementation\n",
    "# X = iris.data[:, (2,3)]\n",
    "# y = iris.target.reshape(-1,1)\n",
    "# w = np.random.uniform(low=0.001, high=1.0, size=(150, 1))\n",
    "# b = np.random.randint(1,5, size=(1))\n",
    "\n",
    "# z = X * w + b\n",
    "\n",
    "# for i in range(1000):\n",
    "#     pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **E2.3 :** Implement the XOR Operator with a Multi-Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(z:np.int32) -> np.int32:\n",
    "    return 0 if z < 0 else 1\n",
    "\n",
    "def input_x() -> tuple:\n",
    "    # Input binary values\n",
    "    while True:\n",
    "        try:\n",
    "            input_x1 = int(input(\"Enter x1 bits: \"), 2)\n",
    "            input_x2 = int(input(\"Enter x2 bits: \"), 2)\n",
    "            break\n",
    "        except ValueError:\n",
    "            print(\"Invalid bit. Input only binary values\")\n",
    "    return input_x1, input_x2\n",
    "\n",
    "def init_params() -> tuple:\n",
    "    w1 = tf.cast(tf.constant([1, 1]), tf.float32)\n",
    "    w2 = tf.cast(tf.constant([-1, 1]), tf.float32)\n",
    "    b1 = tf.constant([-1.5, -0.5])\n",
    "    b2 = tf.constant([-0.5])\n",
    "    return w1, w2, b1, b2\n",
    "\n",
    "def forward_prop(w, x, b) -> tf.float:\n",
    "    return tf.reduce_sum(tf.multiply(w,x)) + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1: 0\n",
      "x2: 0\n",
      "y: 0\n"
     ]
    }
   ],
   "source": [
    "x1, x2 = input_x()\n",
    "w1, w2, b1, b2 = init_params()\n",
    "z11 = forward_prop(w1, tf.cast(tf.constant([x1, x2]), tf.float32), b1[0])\n",
    "z12 = forward_prop(w1, tf.cast(tf.constant([x1, x2]), tf.float32), b1[1])\n",
    "# print(f'Z1: {z11} | Z2: {z12}')\n",
    "\n",
    "# Activation 1st Layer\n",
    "a11, a21 = step(z11), step(z12)\n",
    "# print(f'A11: {a11}, A21: {a21}')\n",
    "\n",
    "# Activation 2nd Layer\n",
    "z21 = forward_prop(w2, tf.constant([a11, a21], dtype=tf.float32), b2)\n",
    "# print(f'Z21: {z21}')\n",
    "\n",
    "y = step(z21) \n",
    "\n",
    "print(f'x1: {x1}')\n",
    "print(f'x2: {x2}')\n",
    "print(f'y: {y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Ejercicio 2.4**\n",
    "Implementar un perceptrón multicapa empleando el MLPClassifier de scikit-learn  \n",
    "(sklearn.neural_network.MLPClassifier) como clasificador para el problema XOR.   \n",
    "Emplear una arquitectura con 2 capas ocultas, 4 neuronas en la primer capa y  \n",
    "2 neuronas en la segunda capa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kekaz16/miniconda3/envs/tensorflow/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (800) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input Dataset\n",
    "X = tf.constant([[0,0],\n",
    "                 [0,1],\n",
    "                 [1,0],\n",
    "                 [1,1]])\n",
    "\n",
    "y = tf.constant([0,1,1,0])\n",
    "\n",
    "# Model\n",
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes= [4, 2],\n",
    "    random_state=1,\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=0.0001,\n",
    "    learning_rate='constant',\n",
    "    max_iter=800,\n",
    "    verbose=False)\n",
    "\n",
    "# Training\n",
    "model.fit(X, y)\n",
    "print(\"%0.3f\" % model.score(X,y))\n",
    "\n",
    "# Predict\n",
    "X_test = np.array([[0,1],\n",
    "                   [1,0],\n",
    "                   [0,0]])\n",
    "\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Ejercicio 2.05**\n",
    "Implementar un perceptrón multicapa empleando el MLPRegressor de scikit  \n",
    "learn (sklearn.neural_network.MLPRegressor) para la estimación del valor  \n",
    "medio de vivienda con el conjunto de datos California Housing de scikit learn.  \n",
    "Emplear una arquitectura con 3 capas ocultas, cada una con 50 neuronas y  \n",
    "evaluar el RMSE con datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.5053326657968762\n",
      "Test RMSE: 0.5053326657968762\n"
     ]
    }
   ],
   "source": [
    "# Input Dataset\n",
    "housing = datasets.fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "# Model\n",
    "model = MLPRegressor(\n",
    "    hidden_layer_sizes=[50, 50, 50],\n",
    "    random_state=42,\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=0.0001,\n",
    "    learning_rate='constant',\n",
    "    max_iter=800,\n",
    "    verbose=False)\n",
    "pipeline = make_pipeline(StandardScaler(), model)\n",
    "\n",
    "# Training\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.5053326657968762\n",
      "Test RMSE: 0.521127919557249\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "y_pred_valid = pipeline.predict(X_valid)\n",
    "rmse_valid = mean_squared_error(y_valid, y_pred_valid, squared=False)\n",
    "print(f'Validation RMSE: {rmse_valid}')\n",
    "\n",
    "y_pred_test = pipeline.predict(X_test)\n",
    "rmse_test = mean_squared_error(y_test, y_pred_test, squared=False)\n",
    "print(f'Test RMSE: {rmse_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Ejercicio 2.06:** Implement Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Probabilities: [0.02364054 0.06426166 0.1746813  0.474833   0.02364054 0.06426166\n",
      " 0.1746813 ]\n",
      "Class Output: 3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "output = [1.0, 2.0, 3.0, 4.0, 1.0, 2.0, 3.0]\n",
    "\n",
    "def softmax(Z):\n",
    "    A = np.exp(Z) / np.sum(np.exp(Z))\n",
    "    return A\n",
    "\n",
    "probs = softmax(np.array(output))\n",
    "max_prob = np.argmax(probs)\n",
    "\n",
    "print(f'Output Probabilities: {probs}')\n",
    "print(f'Class Output: {max_prob}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Ejercicio 2.07:** Verify your Keras installed version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phases to build an Image Classifier \n",
    "#### **1) Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "y_train_full = y_train_full.reshape(-1,1); y_test = y_test.reshape(-1,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train_full: (60000, 28, 28)\n",
      "X_test: (10000, 28, 28)\n",
      "y_train_full: (60000, 1)\n",
      "y_test: (10000, 1) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "X_train_full: {X_train_full.shape}\n",
    "X_test: {X_test.shape}\n",
    "y_train_full: {y_train_full.shape}\n",
    "y_test: {y_test.shape} \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full[0,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_valid: (5000, 28, 28)\n",
      "X_train: (55000, 28, 28)\n",
      "y_valid: (5000, 1)\n",
      "y_train: (55000, 1) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Divide pixels by 255, to normalize values between 0 and 1\n",
    "X_valid, X_train = X_train_full[:5000] / 255, X_train_full[5000:] / 255\n",
    "y_valid, y_train = y_train_full[:5000].reshape((-1,1)), y_train_full[5000:].reshape((-1,1))\n",
    "X_test = X_test / 255\n",
    "print(f\"\"\"\n",
    "X_valid: {X_valid.shape}\n",
    "X_train: {X_train.shape}\n",
    "y_valid: {y_valid.shape}\n",
    "y_train: {y_train.shape} \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 7, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = {\n",
    "    0 : \"T-shirt/top\",\n",
    "    1 : \"Trouser\",\n",
    "    2 : \"Pullover\",\n",
    "    3 : \"Dress\", \n",
    "    4 : \"Coat\",\n",
    "    5 : \"Sandal\",\n",
    "    6 : \"Shirt\",\n",
    "    7 : \"Sneaker\",\n",
    "    8 : \"Bag\",\n",
    "    9 : \"Ankle Boot\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.flatten()\n",
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 28, 28)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2) Model Creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for result reproductibility\n",
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=[28,28]))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softamx\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
